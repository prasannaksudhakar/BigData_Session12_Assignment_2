1. How are worker, executor and task related to each other? 
   Worker is responsible to spawn the executors (one or more)
   executor runs the tasks (one or multiple) in threads .

2. What are the key features of Spark? 
    Rich API
    Resilient Distributed Datasets (RDD)
    DAG based execution
    Data caching (In-Memory Processing)
    Strong ecosystem tool support
    Unified platform

3. What is Spark Driver? 
    It connects to the cluster manager to allocate the resources to the applications, run the executors  
    on the node.

4. What are the benefits of Spark over MapReduce? 
    It is less disk intensive.
    In memory processing. 
    All the problems need not be broken down to map and reduce processing is fast.
    Spark is a framework with Scheduling, Monitoring and Distributing applications.
    Spark is a General Unified Engine which can replace many specialized system like mahout, tez,
    Graph lab, Storm etc.

5. What is Spark Executor?
    Executors run task 
    Execute one or more task using threads in a ThreadPool
